[2019-12-23T18:36:39,051][INFO ][logstash.setting.writabledirectory] Creating directory {:setting=>"path.queue", :path=>"data/guid_member/queue"}
[2019-12-23T18:36:39,068][INFO ][logstash.setting.writabledirectory] Creating directory {:setting=>"path.dead_letter_queue", :path=>"data/guid_member/dead_letter_queue"}
[2019-12-23T18:36:39,386][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2019-12-23T18:36:39,398][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.7.0"}
[2019-12-23T18:36:39,432][INFO ][logstash.agent           ] No persistent UUID file found. Generating new UUID {:uuid=>"07d32374-f863-4deb-a8a8-ead408825773", :path=>"data/guid_member/uuid"}
[2019-12-23T18:36:44,889][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch password=><password>, hosts=>[//es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200], index=>"guid_member", id=>"9af4325f455384d3b0908922906cc42fe3bf019f11bbbb5f432f412edb26af01", document_id=>"%{[@metadata][_id]}", user=>"elastic", document_type=>"%{[@metadata][_type]}", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_05147a32-11da-4397-8cef-2cb7971c635a", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ilm_enabled=>false, ilm_rollover_alias=>"logstash", ilm_pattern=>"{now/d}-000001", ilm_policy=>"logstash-policy", action=>"index", ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2019-12-23T18:36:45,085][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>6000, "pipeline.batch.delay"=>50}
[2019-12-23T18:36:45,595][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://elastic:xxxxxx@es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200/]}}
[2019-12-23T18:36:45,901][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://elastic:xxxxxx@es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200/"}
[2019-12-23T18:36:45,964][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2019-12-23T18:36:45,967][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2019-12-23T18:36:45,988][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200"]}
[2019-12-23T18:36:46,008][INFO ][logstash.outputs.elasticsearch] Using default mapping template
[2019-12-23T18:36:46,021][WARN ][logstash.pipeline        ] CAUTION: Recommended inflight events max exceeded! Logstash will run with up to 48000 events in memory in your current configuration. If your message sizes are large this may cause instability with the default heap size. Please consider setting a non-standard heap size, changing the batch size (currently 6000), or changing the number of pipeline workers (currently 8) {:pipeline_id=>"main", :thread=>"#<Thread:0x58e59314 run>"}
[2019-12-23T18:36:46,146][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2019-12-23T18:36:46,242][INFO ][logstash.outputs.elasticsearch] Installing elasticsearch template to _template/logstash
[2019-12-23T18:36:46,598][INFO ][logstash.pipeline        ] Pipeline started successfully {:pipeline_id=>"main", :thread=>"#<Thread:0x58e59314 run>"}
[2019-12-23T18:36:46,683][INFO ][logstash.agent           ] Pipelines running {:count=>1, :running_pipelines=>[:main], :non_running_pipelines=>[]}
[2019-12-23T18:36:46,969][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9601}
[2019-12-23T18:37:47,208][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Elasticsearch password=><password>, size=>10000, hosts=>["es-cn-mp91e59f20002va73.elasticsearch.aliyuncs.com:9200"], query=>"{ \"query\": { \"query_string\": { \"query\": \"*\" } } }", scroll=>"50m", index=>"guid_member", docinfo=>true, id=>"1263b1a575e70b7c6eead500cf79f79f50015be1e9bbec30b5ed106c2933523a", user=>"elastic", enable_metric=>true, codec=><LogStash::Codecs::JSON id=>"json_6bd04c24-f530-46b0-bd6f-4adfe40c42ea", enable_metric=>true, charset=>"UTF-8">, docinfo_target=>"@metadata", docinfo_fields=>["_index", "_type", "_id"], ssl=>false>
  Error: execution expired
  Exception: Faraday::ConnectionFailed
  Stack: org/jruby/ext/socket/RubyTCPSocket.java:119:in `initialize'
org/jruby/RubyIO.java:1155:in `open'
uri:classloader:/META-INF/jruby.home/lib/ruby/stdlib/net/http.rb:941:in `block in connect'
org/jruby/ext/timeout/Timeout.java:99:in `timeout'
org/jruby/ext/timeout/Timeout.java:75:in `timeout'
uri:classloader:/META-INF/jruby.home/lib/ruby/stdlib/net/http.rb:939:in `connect'
uri:classloader:/META-INF/jruby.home/lib/ruby/stdlib/net/http.rb:924:in `do_start'
uri:classloader:/META-INF/jruby.home/lib/ruby/stdlib/net/http.rb:913:in `start'
uri:classloader:/META-INF/jruby.home/lib/ruby/stdlib/net/http.rb:1465:in `request'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/faraday-0.9.2/lib/faraday/adapter/net_http.rb:82:in `perform_request'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/faraday-0.9.2/lib/faraday/adapter/net_http.rb:40:in `block in call'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/faraday-0.9.2/lib/faraday/adapter/net_http.rb:87:in `with_net_http_connection'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/faraday-0.9.2/lib/faraday/adapter/net_http.rb:32:in `call'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/faraday-0.9.2/lib/faraday/rack_builder.rb:139:in `build_response'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/faraday-0.9.2/lib/faraday/connection.rb:377:in `run_request'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/elasticsearch-transport-5.0.5/lib/elasticsearch/transport/transport/http/faraday.rb:23:in `block in perform_request'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/elasticsearch-transport-5.0.5/lib/elasticsearch/transport/transport/base.rb:262:in `perform_request'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/elasticsearch-transport-5.0.5/lib/elasticsearch/transport/transport/http/faraday.rb:20:in `perform_request'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/elasticsearch-transport-5.0.5/lib/elasticsearch/transport/client.rb:131:in `perform_request'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/elasticsearch-api-5.0.5/lib/elasticsearch/api/actions/search.rb:183:in `search'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/logstash-input-elasticsearch-4.3.0/lib/logstash/inputs/elasticsearch.rb:280:in `search_request'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/logstash-input-elasticsearch-4.3.0/lib/logstash/inputs/elasticsearch.rb:228:in `do_run_slice'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/logstash-input-elasticsearch-4.3.0/lib/logstash/inputs/elasticsearch.rb:209:in `do_run'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/logstash-input-elasticsearch-4.3.0/lib/logstash/inputs/elasticsearch.rb:197:in `run'
/home/devops/es/logstash-6.7.0/logstash-core/lib/logstash/pipeline.rb:426:in `inputworker'
/home/devops/es/logstash-6.7.0/logstash-core/lib/logstash/pipeline.rb:420:in `block in start_input'
[2019-12-23T18:37:59,934][WARN ][logstash.runner          ] SIGINT received. Shutting down.
[2019-12-23T18:38:00,133][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2019-12-23T18:38:00,244][ERROR][org.logstash.Logstash    ] org.jruby.exceptions.ThreadKill
[2019-12-23T18:40:46,905][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2019-12-23T18:40:46,918][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.7.0"}
[2019-12-23T18:40:51,593][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch password=><password>, hosts=>[//es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200], index=>"guid_member", id=>"9af4325f455384d3b0908922906cc42fe3bf019f11bbbb5f432f412edb26af01", document_id=>"%{[@metadata][_id]}", user=>"elastic", document_type=>"%{[@metadata][_type]}", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_242fdb24-682c-442a-bb5f-ebfc29cf3a87", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ilm_enabled=>false, ilm_rollover_alias=>"logstash", ilm_pattern=>"{now/d}-000001", ilm_policy=>"logstash-policy", action=>"index", ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2019-12-23T18:40:51,654][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>6000, "pipeline.batch.delay"=>50}
[2019-12-23T18:40:52,058][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://elastic:xxxxxx@es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200/]}}
[2019-12-23T18:40:52,404][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://elastic:xxxxxx@es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200/"}
[2019-12-23T18:40:52,480][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2019-12-23T18:40:52,483][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2019-12-23T18:40:52,505][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200"]}
[2019-12-23T18:40:52,510][INFO ][logstash.outputs.elasticsearch] Using default mapping template
[2019-12-23T18:40:52,527][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2019-12-23T18:40:52,530][WARN ][logstash.pipeline        ] CAUTION: Recommended inflight events max exceeded! Logstash will run with up to 48000 events in memory in your current configuration. If your message sizes are large this may cause instability with the default heap size. Please consider setting a non-standard heap size, changing the batch size (currently 6000), or changing the number of pipeline workers (currently 8) {:pipeline_id=>"main", :thread=>"#<Thread:0x527216e7 run>"}
[2019-12-23T18:40:52,835][INFO ][logstash.pipeline        ] Pipeline started successfully {:pipeline_id=>"main", :thread=>"#<Thread:0x527216e7 run>"}
[2019-12-23T18:40:52,881][INFO ][logstash.agent           ] Pipelines running {:count=>1, :running_pipelines=>[:main], :non_running_pipelines=>[]}
[2019-12-23T18:40:53,125][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2019-12-23T18:41:53,299][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Elasticsearch password=><password>, size=>10000, hosts=>["es-cn-mp91e59f20002va73.elasticsearch.aliyuncs.com:9200"], query=>"{ \"query\": { \"query_string\": { \"query\": \"*\" } } }", scroll=>"50m", index=>"guid_member", docinfo=>true, id=>"1263b1a575e70b7c6eead500cf79f79f50015be1e9bbec30b5ed106c2933523a", user=>"elastic", enable_metric=>true, codec=><LogStash::Codecs::JSON id=>"json_5b2f671d-9efe-4fa9-b5be-79c6772e71e3", enable_metric=>true, charset=>"UTF-8">, docinfo_target=>"@metadata", docinfo_fields=>["_index", "_type", "_id"], ssl=>false>
  Error: execution expired
  Exception: Faraday::ConnectionFailed
  Stack: org/jruby/ext/socket/RubyTCPSocket.java:119:in `initialize'
org/jruby/RubyIO.java:1155:in `open'
uri:classloader:/META-INF/jruby.home/lib/ruby/stdlib/net/http.rb:941:in `block in connect'
org/jruby/ext/timeout/Timeout.java:99:in `timeout'
org/jruby/ext/timeout/Timeout.java:75:in `timeout'
uri:classloader:/META-INF/jruby.home/lib/ruby/stdlib/net/http.rb:939:in `connect'
uri:classloader:/META-INF/jruby.home/lib/ruby/stdlib/net/http.rb:924:in `do_start'
uri:classloader:/META-INF/jruby.home/lib/ruby/stdlib/net/http.rb:913:in `start'
uri:classloader:/META-INF/jruby.home/lib/ruby/stdlib/net/http.rb:1465:in `request'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/faraday-0.9.2/lib/faraday/adapter/net_http.rb:82:in `perform_request'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/faraday-0.9.2/lib/faraday/adapter/net_http.rb:40:in `block in call'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/faraday-0.9.2/lib/faraday/adapter/net_http.rb:87:in `with_net_http_connection'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/faraday-0.9.2/lib/faraday/adapter/net_http.rb:32:in `call'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/faraday-0.9.2/lib/faraday/rack_builder.rb:139:in `build_response'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/faraday-0.9.2/lib/faraday/connection.rb:377:in `run_request'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/elasticsearch-transport-5.0.5/lib/elasticsearch/transport/transport/http/faraday.rb:23:in `block in perform_request'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/elasticsearch-transport-5.0.5/lib/elasticsearch/transport/transport/base.rb:262:in `perform_request'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/elasticsearch-transport-5.0.5/lib/elasticsearch/transport/transport/http/faraday.rb:20:in `perform_request'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/elasticsearch-transport-5.0.5/lib/elasticsearch/transport/client.rb:131:in `perform_request'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/elasticsearch-api-5.0.5/lib/elasticsearch/api/actions/search.rb:183:in `search'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/logstash-input-elasticsearch-4.3.0/lib/logstash/inputs/elasticsearch.rb:280:in `search_request'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/logstash-input-elasticsearch-4.3.0/lib/logstash/inputs/elasticsearch.rb:228:in `do_run_slice'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/logstash-input-elasticsearch-4.3.0/lib/logstash/inputs/elasticsearch.rb:209:in `do_run'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/logstash-input-elasticsearch-4.3.0/lib/logstash/inputs/elasticsearch.rb:197:in `run'
/home/devops/es/logstash-6.7.0/logstash-core/lib/logstash/pipeline.rb:426:in `inputworker'
/home/devops/es/logstash-6.7.0/logstash-core/lib/logstash/pipeline.rb:420:in `block in start_input'
[2019-12-23T18:42:14,848][WARN ][logstash.runner          ] SIGINT received. Shutting down.
[2019-12-23T18:42:15,028][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2019-12-23T18:42:15,189][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2019-12-23T18:42:15,278][ERROR][org.logstash.Logstash    ] org.jruby.exceptions.ThreadKill
[2019-12-23T18:44:35,180][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2019-12-23T18:44:35,192][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.7.0"}
[2019-12-23T18:44:39,830][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch password=><password>, hosts=>[//es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200], index=>"guid_member", id=>"9af4325f455384d3b0908922906cc42fe3bf019f11bbbb5f432f412edb26af01", document_id=>"%{[@metadata][_id]}", user=>"elastic", document_type=>"%{[@metadata][_type]}", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_c6faa9c2-5afc-41f2-a9b8-35165c5ef0b5", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ilm_enabled=>false, ilm_rollover_alias=>"logstash", ilm_pattern=>"{now/d}-000001", ilm_policy=>"logstash-policy", action=>"index", ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2019-12-23T18:44:39,905][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>6000, "pipeline.batch.delay"=>50}
[2019-12-23T18:44:40,309][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://elastic:xxxxxx@es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200/]}}
[2019-12-23T18:44:40,555][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://elastic:xxxxxx@es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200/"}
[2019-12-23T18:44:40,632][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2019-12-23T18:44:40,636][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2019-12-23T18:44:40,660][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200"]}
[2019-12-23T18:44:40,664][INFO ][logstash.outputs.elasticsearch] Using default mapping template
[2019-12-23T18:44:40,682][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2019-12-23T18:44:40,684][WARN ][logstash.pipeline        ] CAUTION: Recommended inflight events max exceeded! Logstash will run with up to 48000 events in memory in your current configuration. If your message sizes are large this may cause instability with the default heap size. Please consider setting a non-standard heap size, changing the batch size (currently 6000), or changing the number of pipeline workers (currently 8) {:pipeline_id=>"main", :thread=>"#<Thread:0x537471f1 run>"}
[2019-12-23T18:44:41,046][INFO ][logstash.pipeline        ] Pipeline started successfully {:pipeline_id=>"main", :thread=>"#<Thread:0x537471f1 sleep>"}
[2019-12-23T18:44:41,090][INFO ][logstash.agent           ] Pipelines running {:count=>1, :running_pipelines=>[:main], :non_running_pipelines=>[]}
[2019-12-23T18:44:41,328][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2019-12-23T18:45:41,465][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Elasticsearch password=><password>, size=>10000, hosts=>["es-cn-mp91e59f20002va73.elasticsearch.aliyuncs.com:9200"], query=>"{ \"query\": { \"query_string\": { \"query\": \"*\" } } }", scroll=>"50m", index=>"guid_member", docinfo=>true, id=>"1263b1a575e70b7c6eead500cf79f79f50015be1e9bbec30b5ed106c2933523a", user=>"elastic", enable_metric=>true, codec=><LogStash::Codecs::JSON id=>"json_9127a64b-ae86-435f-babd-5828772dd1a0", enable_metric=>true, charset=>"UTF-8">, docinfo_target=>"@metadata", docinfo_fields=>["_index", "_type", "_id"], ssl=>false>
  Error: execution expired
  Exception: Faraday::ConnectionFailed
  Stack: org/jruby/ext/socket/RubyTCPSocket.java:119:in `initialize'
org/jruby/RubyIO.java:1155:in `open'
uri:classloader:/META-INF/jruby.home/lib/ruby/stdlib/net/http.rb:941:in `block in connect'
org/jruby/ext/timeout/Timeout.java:99:in `timeout'
org/jruby/ext/timeout/Timeout.java:75:in `timeout'
uri:classloader:/META-INF/jruby.home/lib/ruby/stdlib/net/http.rb:939:in `connect'
uri:classloader:/META-INF/jruby.home/lib/ruby/stdlib/net/http.rb:924:in `do_start'
uri:classloader:/META-INF/jruby.home/lib/ruby/stdlib/net/http.rb:913:in `start'
uri:classloader:/META-INF/jruby.home/lib/ruby/stdlib/net/http.rb:1465:in `request'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/faraday-0.9.2/lib/faraday/adapter/net_http.rb:82:in `perform_request'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/faraday-0.9.2/lib/faraday/adapter/net_http.rb:40:in `block in call'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/faraday-0.9.2/lib/faraday/adapter/net_http.rb:87:in `with_net_http_connection'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/faraday-0.9.2/lib/faraday/adapter/net_http.rb:32:in `call'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/faraday-0.9.2/lib/faraday/rack_builder.rb:139:in `build_response'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/faraday-0.9.2/lib/faraday/connection.rb:377:in `run_request'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/elasticsearch-transport-5.0.5/lib/elasticsearch/transport/transport/http/faraday.rb:23:in `block in perform_request'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/elasticsearch-transport-5.0.5/lib/elasticsearch/transport/transport/base.rb:262:in `perform_request'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/elasticsearch-transport-5.0.5/lib/elasticsearch/transport/transport/http/faraday.rb:20:in `perform_request'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/elasticsearch-transport-5.0.5/lib/elasticsearch/transport/client.rb:131:in `perform_request'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/elasticsearch-api-5.0.5/lib/elasticsearch/api/actions/search.rb:183:in `search'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/logstash-input-elasticsearch-4.3.0/lib/logstash/inputs/elasticsearch.rb:280:in `search_request'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/logstash-input-elasticsearch-4.3.0/lib/logstash/inputs/elasticsearch.rb:228:in `do_run_slice'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/logstash-input-elasticsearch-4.3.0/lib/logstash/inputs/elasticsearch.rb:209:in `do_run'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/logstash-input-elasticsearch-4.3.0/lib/logstash/inputs/elasticsearch.rb:197:in `run'
/home/devops/es/logstash-6.7.0/logstash-core/lib/logstash/pipeline.rb:426:in `inputworker'
/home/devops/es/logstash-6.7.0/logstash-core/lib/logstash/pipeline.rb:420:in `block in start_input'
[2019-12-23T18:45:49,190][WARN ][logstash.runner          ] SIGINT received. Shutting down.
[2019-12-23T18:45:49,393][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2019-12-23T18:45:49,489][ERROR][org.logstash.Logstash    ] org.jruby.exceptions.ThreadKill
[2019-12-23T18:46:04,839][INFO ][logstash.setting.writabledirectory] Creating directory {:setting=>"path.queue", :path=>"data/summary_hour_behavior_log/queue"}
[2019-12-23T18:46:04,847][INFO ][logstash.setting.writabledirectory] Creating directory {:setting=>"path.dead_letter_queue", :path=>"data/summary_hour_behavior_log/dead_letter_queue"}
[2019-12-23T18:46:05,164][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2019-12-23T18:46:05,171][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.7.0"}
[2019-12-23T18:46:05,191][INFO ][logstash.agent           ] No persistent UUID file found. Generating new UUID {:uuid=>"7c9f6335-393b-4529-9962-85c67e98fd11", :path=>"data/summary_hour_behavior_log/uuid"}
[2019-12-23T18:46:07,889][WARN ][logstash.runner          ] SIGINT received. Shutting down.
[2019-12-23T18:46:08,910][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2019-12-23T18:46:09,084][ERROR][org.logstash.Logstash    ] org.jruby.exceptions.ThreadKill
[2019-12-23T19:21:38,197][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2019-12-23T19:21:38,210][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.7.0"}
[2019-12-23T19:21:42,709][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch password=><password>, hosts=>[//es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200], index=>"guid_member", id=>"9af4325f455384d3b0908922906cc42fe3bf019f11bbbb5f432f412edb26af01", document_id=>"%{[@metadata][_id]}", user=>"elastic", document_type=>"%{[@metadata][_type]}", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_6a9dbe87-c291-46d5-8e81-14a2a2e6a6ce", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ilm_enabled=>false, ilm_rollover_alias=>"logstash", ilm_pattern=>"{now/d}-000001", ilm_policy=>"logstash-policy", action=>"index", ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2019-12-23T19:21:42,766][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>6000, "pipeline.batch.delay"=>50}
[2019-12-23T19:21:43,128][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://elastic:xxxxxx@es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200/]}}
[2019-12-23T19:21:43,413][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://elastic:xxxxxx@es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200/"}
[2019-12-23T19:21:43,465][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2019-12-23T19:21:43,467][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2019-12-23T19:21:43,498][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200"]}
[2019-12-23T19:21:43,504][INFO ][logstash.outputs.elasticsearch] Using default mapping template
[2019-12-23T19:21:43,525][WARN ][logstash.pipeline        ] CAUTION: Recommended inflight events max exceeded! Logstash will run with up to 48000 events in memory in your current configuration. If your message sizes are large this may cause instability with the default heap size. Please consider setting a non-standard heap size, changing the batch size (currently 6000), or changing the number of pipeline workers (currently 8) {:pipeline_id=>"main", :thread=>"#<Thread:0x581ca33d run>"}
[2019-12-23T19:21:43,547][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2019-12-23T19:21:43,858][INFO ][logstash.pipeline        ] Pipeline started successfully {:pipeline_id=>"main", :thread=>"#<Thread:0x581ca33d run>"}
[2019-12-23T19:21:43,908][INFO ][logstash.agent           ] Pipelines running {:count=>1, :running_pipelines=>[:main], :non_running_pipelines=>[]}
[2019-12-23T19:21:44,134][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2019-12-23T19:22:44,217][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Elasticsearch password=><password>, size=>10000, hosts=>["es-cn-mp91e59f20002va73.elasticsearch.aliyuncs.com:9200"], query=>"{ \"query\": { \"query_string\": { \"query\": \"*\" } } }", scroll=>"50m", index=>"guid_member", docinfo=>true, id=>"1263b1a575e70b7c6eead500cf79f79f50015be1e9bbec30b5ed106c2933523a", user=>"elastic", enable_metric=>true, codec=><LogStash::Codecs::JSON id=>"json_ae0b84f5-8b49-462b-a76d-4b106d111e6e", enable_metric=>true, charset=>"UTF-8">, docinfo_target=>"@metadata", docinfo_fields=>["_index", "_type", "_id"], ssl=>false>
  Error: execution expired
  Exception: Faraday::ConnectionFailed
  Stack: org/jruby/ext/socket/RubyTCPSocket.java:119:in `initialize'
org/jruby/RubyIO.java:1155:in `open'
uri:classloader:/META-INF/jruby.home/lib/ruby/stdlib/net/http.rb:941:in `block in connect'
org/jruby/ext/timeout/Timeout.java:99:in `timeout'
org/jruby/ext/timeout/Timeout.java:75:in `timeout'
uri:classloader:/META-INF/jruby.home/lib/ruby/stdlib/net/http.rb:939:in `connect'
uri:classloader:/META-INF/jruby.home/lib/ruby/stdlib/net/http.rb:924:in `do_start'
uri:classloader:/META-INF/jruby.home/lib/ruby/stdlib/net/http.rb:913:in `start'
uri:classloader:/META-INF/jruby.home/lib/ruby/stdlib/net/http.rb:1465:in `request'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/faraday-0.9.2/lib/faraday/adapter/net_http.rb:82:in `perform_request'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/faraday-0.9.2/lib/faraday/adapter/net_http.rb:40:in `block in call'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/faraday-0.9.2/lib/faraday/adapter/net_http.rb:87:in `with_net_http_connection'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/faraday-0.9.2/lib/faraday/adapter/net_http.rb:32:in `call'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/faraday-0.9.2/lib/faraday/rack_builder.rb:139:in `build_response'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/faraday-0.9.2/lib/faraday/connection.rb:377:in `run_request'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/elasticsearch-transport-5.0.5/lib/elasticsearch/transport/transport/http/faraday.rb:23:in `block in perform_request'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/elasticsearch-transport-5.0.5/lib/elasticsearch/transport/transport/base.rb:262:in `perform_request'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/elasticsearch-transport-5.0.5/lib/elasticsearch/transport/transport/http/faraday.rb:20:in `perform_request'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/elasticsearch-transport-5.0.5/lib/elasticsearch/transport/client.rb:131:in `perform_request'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/elasticsearch-api-5.0.5/lib/elasticsearch/api/actions/search.rb:183:in `search'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/logstash-input-elasticsearch-4.3.0/lib/logstash/inputs/elasticsearch.rb:280:in `search_request'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/logstash-input-elasticsearch-4.3.0/lib/logstash/inputs/elasticsearch.rb:228:in `do_run_slice'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/logstash-input-elasticsearch-4.3.0/lib/logstash/inputs/elasticsearch.rb:209:in `do_run'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/logstash-input-elasticsearch-4.3.0/lib/logstash/inputs/elasticsearch.rb:197:in `run'
/home/devops/es/logstash-6.7.0/logstash-core/lib/logstash/pipeline.rb:426:in `inputworker'
/home/devops/es/logstash-6.7.0/logstash-core/lib/logstash/pipeline.rb:420:in `block in start_input'
[2019-12-23T19:22:46,704][WARN ][logstash.runner          ] SIGINT received. Shutting down.
[2019-12-23T19:22:46,858][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2019-12-23T19:22:47,005][ERROR][org.logstash.Logstash    ] org.jruby.exceptions.ThreadKill
[2019-12-23T19:25:11,001][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2019-12-23T19:25:11,014][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.7.0"}
[2019-12-23T19:25:15,499][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch password=><password>, hosts=>[//es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200], index=>"guid_member", id=>"9af4325f455384d3b0908922906cc42fe3bf019f11bbbb5f432f412edb26af01", document_id=>"%{[@metadata][_id]}", user=>"elastic", document_type=>"%{[@metadata][_type]}", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_c6a90b33-903d-4017-ae12-b89b0f532130", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ilm_enabled=>false, ilm_rollover_alias=>"logstash", ilm_pattern=>"{now/d}-000001", ilm_policy=>"logstash-policy", action=>"index", ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2019-12-23T19:25:15,562][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>6000, "pipeline.batch.delay"=>50}
[2019-12-23T19:25:15,944][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://elastic:xxxxxx@es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200/]}}
[2019-12-23T19:25:16,225][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://elastic:xxxxxx@es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200/"}
[2019-12-23T19:25:16,291][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2019-12-23T19:25:16,294][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2019-12-23T19:25:16,328][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200"]}
[2019-12-23T19:25:16,333][INFO ][logstash.outputs.elasticsearch] Using default mapping template
[2019-12-23T19:25:16,363][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2019-12-23T19:25:16,364][WARN ][logstash.pipeline        ] CAUTION: Recommended inflight events max exceeded! Logstash will run with up to 48000 events in memory in your current configuration. If your message sizes are large this may cause instability with the default heap size. Please consider setting a non-standard heap size, changing the batch size (currently 6000), or changing the number of pipeline workers (currently 8) {:pipeline_id=>"main", :thread=>"#<Thread:0x55e57e9a run>"}
[2019-12-23T19:25:16,730][INFO ][logstash.pipeline        ] Pipeline started successfully {:pipeline_id=>"main", :thread=>"#<Thread:0x55e57e9a run>"}
[2019-12-23T19:25:16,772][INFO ][logstash.agent           ] Pipelines running {:count=>1, :running_pipelines=>[:main], :non_running_pipelines=>[]}
[2019-12-23T19:25:17,003][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2019-12-23T19:26:17,153][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Elasticsearch password=><password>, size=>10000, hosts=>["es-cn-mp91e59f20002va73.elasticsearch.aliyuncs.com:9200"], query=>"{ \"query\": { \"query_string\": { \"query\": \"*\" } } }", scroll=>"50m", index=>"guid_member", docinfo=>true, id=>"1263b1a575e70b7c6eead500cf79f79f50015be1e9bbec30b5ed106c2933523a", user=>"elastic", enable_metric=>true, codec=><LogStash::Codecs::JSON id=>"json_1b637630-d24e-4a37-99f7-e988217576d3", enable_metric=>true, charset=>"UTF-8">, docinfo_target=>"@metadata", docinfo_fields=>["_index", "_type", "_id"], ssl=>false>
  Error: execution expired
  Exception: Faraday::ConnectionFailed
  Stack: org/jruby/ext/socket/RubyTCPSocket.java:119:in `initialize'
org/jruby/RubyIO.java:1155:in `open'
uri:classloader:/META-INF/jruby.home/lib/ruby/stdlib/net/http.rb:941:in `block in connect'
org/jruby/ext/timeout/Timeout.java:99:in `timeout'
org/jruby/ext/timeout/Timeout.java:75:in `timeout'
uri:classloader:/META-INF/jruby.home/lib/ruby/stdlib/net/http.rb:939:in `connect'
uri:classloader:/META-INF/jruby.home/lib/ruby/stdlib/net/http.rb:924:in `do_start'
uri:classloader:/META-INF/jruby.home/lib/ruby/stdlib/net/http.rb:913:in `start'
uri:classloader:/META-INF/jruby.home/lib/ruby/stdlib/net/http.rb:1465:in `request'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/faraday-0.9.2/lib/faraday/adapter/net_http.rb:82:in `perform_request'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/faraday-0.9.2/lib/faraday/adapter/net_http.rb:40:in `block in call'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/faraday-0.9.2/lib/faraday/adapter/net_http.rb:87:in `with_net_http_connection'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/faraday-0.9.2/lib/faraday/adapter/net_http.rb:32:in `call'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/faraday-0.9.2/lib/faraday/rack_builder.rb:139:in `build_response'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/faraday-0.9.2/lib/faraday/connection.rb:377:in `run_request'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/elasticsearch-transport-5.0.5/lib/elasticsearch/transport/transport/http/faraday.rb:23:in `block in perform_request'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/elasticsearch-transport-5.0.5/lib/elasticsearch/transport/transport/base.rb:262:in `perform_request'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/elasticsearch-transport-5.0.5/lib/elasticsearch/transport/transport/http/faraday.rb:20:in `perform_request'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/elasticsearch-transport-5.0.5/lib/elasticsearch/transport/client.rb:131:in `perform_request'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/elasticsearch-api-5.0.5/lib/elasticsearch/api/actions/search.rb:183:in `search'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/logstash-input-elasticsearch-4.3.0/lib/logstash/inputs/elasticsearch.rb:280:in `search_request'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/logstash-input-elasticsearch-4.3.0/lib/logstash/inputs/elasticsearch.rb:228:in `do_run_slice'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/logstash-input-elasticsearch-4.3.0/lib/logstash/inputs/elasticsearch.rb:209:in `do_run'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/logstash-input-elasticsearch-4.3.0/lib/logstash/inputs/elasticsearch.rb:197:in `run'
/home/devops/es/logstash-6.7.0/logstash-core/lib/logstash/pipeline.rb:426:in `inputworker'
/home/devops/es/logstash-6.7.0/logstash-core/lib/logstash/pipeline.rb:420:in `block in start_input'
[2019-12-23T19:27:18,181][ERROR][logstash.pipeline        ] A plugin had an unrecoverable error. Will restart this plugin.
  Pipeline_id:main
  Plugin: <LogStash::Inputs::Elasticsearch password=><password>, size=>10000, hosts=>["es-cn-mp91e59f20002va73.elasticsearch.aliyuncs.com:9200"], query=>"{ \"query\": { \"query_string\": { \"query\": \"*\" } } }", scroll=>"50m", index=>"guid_member", docinfo=>true, id=>"1263b1a575e70b7c6eead500cf79f79f50015be1e9bbec30b5ed106c2933523a", user=>"elastic", enable_metric=>true, codec=><LogStash::Codecs::JSON id=>"json_1b637630-d24e-4a37-99f7-e988217576d3", enable_metric=>true, charset=>"UTF-8">, docinfo_target=>"@metadata", docinfo_fields=>["_index", "_type", "_id"], ssl=>false>
  Error: execution expired
  Exception: Faraday::ConnectionFailed
  Stack: org/jruby/ext/socket/RubyTCPSocket.java:119:in `initialize'
org/jruby/RubyIO.java:1155:in `open'
uri:classloader:/META-INF/jruby.home/lib/ruby/stdlib/net/http.rb:941:in `block in connect'
org/jruby/ext/timeout/Timeout.java:99:in `timeout'
org/jruby/ext/timeout/Timeout.java:75:in `timeout'
uri:classloader:/META-INF/jruby.home/lib/ruby/stdlib/net/http.rb:939:in `connect'
uri:classloader:/META-INF/jruby.home/lib/ruby/stdlib/net/http.rb:924:in `do_start'
uri:classloader:/META-INF/jruby.home/lib/ruby/stdlib/net/http.rb:913:in `start'
uri:classloader:/META-INF/jruby.home/lib/ruby/stdlib/net/http.rb:1465:in `request'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/faraday-0.9.2/lib/faraday/adapter/net_http.rb:82:in `perform_request'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/faraday-0.9.2/lib/faraday/adapter/net_http.rb:40:in `block in call'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/faraday-0.9.2/lib/faraday/adapter/net_http.rb:87:in `with_net_http_connection'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/faraday-0.9.2/lib/faraday/adapter/net_http.rb:32:in `call'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/faraday-0.9.2/lib/faraday/rack_builder.rb:139:in `build_response'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/faraday-0.9.2/lib/faraday/connection.rb:377:in `run_request'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/elasticsearch-transport-5.0.5/lib/elasticsearch/transport/transport/http/faraday.rb:23:in `block in perform_request'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/elasticsearch-transport-5.0.5/lib/elasticsearch/transport/transport/base.rb:262:in `perform_request'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/elasticsearch-transport-5.0.5/lib/elasticsearch/transport/transport/http/faraday.rb:20:in `perform_request'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/elasticsearch-transport-5.0.5/lib/elasticsearch/transport/client.rb:131:in `perform_request'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/elasticsearch-api-5.0.5/lib/elasticsearch/api/actions/search.rb:183:in `search'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/logstash-input-elasticsearch-4.3.0/lib/logstash/inputs/elasticsearch.rb:280:in `search_request'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/logstash-input-elasticsearch-4.3.0/lib/logstash/inputs/elasticsearch.rb:228:in `do_run_slice'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/logstash-input-elasticsearch-4.3.0/lib/logstash/inputs/elasticsearch.rb:209:in `do_run'
/home/devops/es/logstash-6.7.0/vendor/bundle/jruby/2.5.0/gems/logstash-input-elasticsearch-4.3.0/lib/logstash/inputs/elasticsearch.rb:197:in `run'
/home/devops/es/logstash-6.7.0/logstash-core/lib/logstash/pipeline.rb:426:in `inputworker'
/home/devops/es/logstash-6.7.0/logstash-core/lib/logstash/pipeline.rb:420:in `block in start_input'
[2019-12-23T19:27:32,172][WARN ][logstash.runner          ] SIGINT received. Shutting down.
[2019-12-23T19:27:32,353][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2019-12-23T19:27:32,466][ERROR][org.logstash.Logstash    ] org.jruby.exceptions.ThreadKill
[2019-12-23T19:28:20,991][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2019-12-23T19:28:21,003][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.7.0"}
[2019-12-23T19:28:25,467][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch password=><password>, hosts=>[//es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200], index=>"guid_member", id=>"9af4325f455384d3b0908922906cc42fe3bf019f11bbbb5f432f412edb26af01", document_id=>"%{[@metadata][_id]}", user=>"elastic", document_type=>"%{[@metadata][_type]}", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_d2ea03be-ed13-4c1f-a016-f0a0b5dbe0ba", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ilm_enabled=>false, ilm_rollover_alias=>"logstash", ilm_pattern=>"{now/d}-000001", ilm_policy=>"logstash-policy", action=>"index", ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2019-12-23T19:28:25,542][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>6000, "pipeline.batch.delay"=>50}
[2019-12-23T19:28:25,972][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://elastic:xxxxxx@es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200/]}}
[2019-12-23T19:28:26,192][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://elastic:xxxxxx@es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200/"}
[2019-12-23T19:28:26,240][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2019-12-23T19:28:26,242][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2019-12-23T19:28:26,269][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200"]}
[2019-12-23T19:28:26,278][INFO ][logstash.outputs.elasticsearch] Using default mapping template
[2019-12-23T19:28:26,297][WARN ][logstash.pipeline        ] CAUTION: Recommended inflight events max exceeded! Logstash will run with up to 48000 events in memory in your current configuration. If your message sizes are large this may cause instability with the default heap size. Please consider setting a non-standard heap size, changing the batch size (currently 6000), or changing the number of pipeline workers (currently 8) {:pipeline_id=>"main", :thread=>"#<Thread:0x1cb79bba run>"}
[2019-12-23T19:28:26,320][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2019-12-23T19:28:26,655][INFO ][logstash.pipeline        ] Pipeline started successfully {:pipeline_id=>"main", :thread=>"#<Thread:0x1cb79bba run>"}
[2019-12-23T19:28:26,707][INFO ][logstash.agent           ] Pipelines running {:count=>1, :running_pipelines=>[:main], :non_running_pipelines=>[]}
[2019-12-23T19:28:27,001][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2019-12-23T19:28:30,275][INFO ][logstash.pipeline        ] Pipeline has terminated {:pipeline_id=>"main", :thread=>"#<Thread:0x1cb79bba run>"}
[2019-12-23T19:28:44,128][INFO ][logstash.setting.writabledirectory] Creating directory {:setting=>"path.queue", :path=>"data/promotion_plan_fans/queue"}
[2019-12-23T19:28:44,133][INFO ][logstash.setting.writabledirectory] Creating directory {:setting=>"path.dead_letter_queue", :path=>"data/promotion_plan_fans/dead_letter_queue"}
[2019-12-23T19:28:44,413][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2019-12-23T19:28:44,421][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.7.0"}
[2019-12-23T19:28:44,444][INFO ][logstash.agent           ] No persistent UUID file found. Generating new UUID {:uuid=>"2504e972-e462-4f75-9a22-72cc0d3ddbf1", :path=>"data/promotion_plan_fans/uuid"}
[2019-12-23T19:28:48,954][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch password=><password>, hosts=>[//es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200], index=>"promotion_plan_fans", id=>"d5f9f0dd81bbe278073a9ef6351d53163969c96509c853a4fad3d0138d71c03a", document_id=>"%{[@metadata][_id]}", user=>"elastic", document_type=>"%{[@metadata][_type]}", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_7f6fb78b-909e-4218-9595-ab5cacce484d", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ilm_enabled=>false, ilm_rollover_alias=>"logstash", ilm_pattern=>"{now/d}-000001", ilm_policy=>"logstash-policy", action=>"index", ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2019-12-23T19:28:49,019][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>6000, "pipeline.batch.delay"=>50}
[2019-12-23T19:28:49,396][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://elastic:xxxxxx@es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200/]}}
[2019-12-23T19:28:49,596][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://elastic:xxxxxx@es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200/"}
[2019-12-23T19:28:49,641][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2019-12-23T19:28:49,643][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2019-12-23T19:28:49,660][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200"]}
[2019-12-23T19:28:49,668][INFO ][logstash.outputs.elasticsearch] Using default mapping template
[2019-12-23T19:28:49,684][WARN ][logstash.pipeline        ] CAUTION: Recommended inflight events max exceeded! Logstash will run with up to 48000 events in memory in your current configuration. If your message sizes are large this may cause instability with the default heap size. Please consider setting a non-standard heap size, changing the batch size (currently 6000), or changing the number of pipeline workers (currently 8) {:pipeline_id=>"main", :thread=>"#<Thread:0x1550a833 run>"}
[2019-12-23T19:28:49,683][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2019-12-23T19:28:50,095][INFO ][logstash.pipeline        ] Pipeline started successfully {:pipeline_id=>"main", :thread=>"#<Thread:0x1550a833 run>"}
[2019-12-23T19:28:50,138][INFO ][logstash.agent           ] Pipelines running {:count=>1, :running_pipelines=>[:main], :non_running_pipelines=>[]}
[2019-12-23T19:28:50,406][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2019-12-23T19:28:51,666][INFO ][logstash.pipeline        ] Pipeline has terminated {:pipeline_id=>"main", :thread=>"#<Thread:0x1550a833 run>"}
[2019-12-23T19:29:04,677][INFO ][logstash.setting.writabledirectory] Creating directory {:setting=>"path.queue", :path=>"data/app_event_push_log/queue"}
[2019-12-23T19:29:04,685][INFO ][logstash.setting.writabledirectory] Creating directory {:setting=>"path.dead_letter_queue", :path=>"data/app_event_push_log/dead_letter_queue"}
[2019-12-23T19:29:05,065][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2019-12-23T19:29:05,074][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.7.0"}
[2019-12-23T19:29:05,105][INFO ][logstash.agent           ] No persistent UUID file found. Generating new UUID {:uuid=>"f85bde37-012d-4637-9c19-c7d019d0827c", :path=>"data/app_event_push_log/uuid"}
[2019-12-23T19:29:09,842][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch password=><password>, hosts=>[//es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200], index=>"app_event_push_log", id=>"224286a46a8cb59db3e421e31a509cb4eec60ba80fe90dec10f2d29751736706", document_id=>"%{[@metadata][_id]}", user=>"elastic", document_type=>"%{[@metadata][_type]}", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_187b8612-3bf9-417c-8fde-78b1212eb793", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ilm_enabled=>false, ilm_rollover_alias=>"logstash", ilm_pattern=>"{now/d}-000001", ilm_policy=>"logstash-policy", action=>"index", ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2019-12-23T19:29:09,905][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>6000, "pipeline.batch.delay"=>50}
[2019-12-23T19:29:10,327][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://elastic:xxxxxx@es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200/]}}
[2019-12-23T19:29:10,554][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://elastic:xxxxxx@es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200/"}
[2019-12-23T19:29:10,617][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2019-12-23T19:29:10,627][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2019-12-23T19:29:10,649][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200"]}
[2019-12-23T19:29:10,660][INFO ][logstash.outputs.elasticsearch] Using default mapping template
[2019-12-23T19:29:10,674][WARN ][logstash.pipeline        ] CAUTION: Recommended inflight events max exceeded! Logstash will run with up to 48000 events in memory in your current configuration. If your message sizes are large this may cause instability with the default heap size. Please consider setting a non-standard heap size, changing the batch size (currently 6000), or changing the number of pipeline workers (currently 8) {:pipeline_id=>"main", :thread=>"#<Thread:0x15d0489f run>"}
[2019-12-23T19:29:10,678][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2019-12-23T19:29:10,958][INFO ][logstash.pipeline        ] Pipeline started successfully {:pipeline_id=>"main", :thread=>"#<Thread:0x15d0489f run>"}
[2019-12-23T19:29:11,005][INFO ][logstash.agent           ] Pipelines running {:count=>1, :running_pipelines=>[:main], :non_running_pipelines=>[]}
[2019-12-23T19:29:11,247][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2019-12-23T19:55:26,618][INFO ][logstash.pipeline        ] Pipeline has terminated {:pipeline_id=>"main", :thread=>"#<Thread:0x15d0489f run>"}
[2019-12-23T19:55:40,631][INFO ][logstash.setting.writabledirectory] Creating directory {:setting=>"path.queue", :path=>"data/im_like_info/queue"}
[2019-12-23T19:55:40,637][INFO ][logstash.setting.writabledirectory] Creating directory {:setting=>"path.dead_letter_queue", :path=>"data/im_like_info/dead_letter_queue"}
[2019-12-23T19:55:40,969][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2019-12-23T19:55:40,979][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.7.0"}
[2019-12-23T19:55:41,011][INFO ][logstash.agent           ] No persistent UUID file found. Generating new UUID {:uuid=>"8ca4ad2a-faf1-4c2f-9ac3-9e1b6d5df6a3", :path=>"data/im_like_info/uuid"}
[2019-12-23T19:55:45,615][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch password=><password>, hosts=>[//es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200], index=>"im_like_info", id=>"5f3749d23de808d9ef00a1f4e95e9c4bb94c4fd609ff3f11364b9aaeab75948a", document_id=>"%{[@metadata][_id]}", user=>"elastic", document_type=>"%{[@metadata][_type]}", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_284dd0a2-0053-447e-8813-991a91ac9714", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ilm_enabled=>false, ilm_rollover_alias=>"logstash", ilm_pattern=>"{now/d}-000001", ilm_policy=>"logstash-policy", action=>"index", ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2019-12-23T19:55:45,675][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>6000, "pipeline.batch.delay"=>50}
[2019-12-23T19:55:46,035][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://elastic:xxxxxx@es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200/]}}
[2019-12-23T19:55:46,231][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://elastic:xxxxxx@es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200/"}
[2019-12-23T19:55:46,279][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2019-12-23T19:55:46,284][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2019-12-23T19:55:46,309][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200"]}
[2019-12-23T19:55:46,321][INFO ][logstash.outputs.elasticsearch] Using default mapping template
[2019-12-23T19:55:46,332][WARN ][logstash.pipeline        ] CAUTION: Recommended inflight events max exceeded! Logstash will run with up to 48000 events in memory in your current configuration. If your message sizes are large this may cause instability with the default heap size. Please consider setting a non-standard heap size, changing the batch size (currently 6000), or changing the number of pipeline workers (currently 8) {:pipeline_id=>"main", :thread=>"#<Thread:0x63cea7f3 run>"}
[2019-12-23T19:55:46,349][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2019-12-23T19:55:46,731][INFO ][logstash.pipeline        ] Pipeline started successfully {:pipeline_id=>"main", :thread=>"#<Thread:0x63cea7f3 run>"}
[2019-12-23T19:55:46,783][INFO ][logstash.agent           ] Pipelines running {:count=>1, :running_pipelines=>[:main], :non_running_pipelines=>[]}
[2019-12-23T19:55:47,053][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2019-12-23T19:55:58,434][INFO ][logstash.pipeline        ] Pipeline has terminated {:pipeline_id=>"main", :thread=>"#<Thread:0x63cea7f3 run>"}
[2019-12-23T19:56:11,947][INFO ][logstash.setting.writabledirectory] Creating directory {:setting=>"path.queue", :path=>"data/im_chat_info/queue"}
[2019-12-23T19:56:11,954][INFO ][logstash.setting.writabledirectory] Creating directory {:setting=>"path.dead_letter_queue", :path=>"data/im_chat_info/dead_letter_queue"}
[2019-12-23T19:56:12,277][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2019-12-23T19:56:12,286][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.7.0"}
[2019-12-23T19:56:12,307][INFO ][logstash.agent           ] No persistent UUID file found. Generating new UUID {:uuid=>"33c38910-d1e6-4e4a-b817-9004878ebbb6", :path=>"data/im_chat_info/uuid"}
[2019-12-23T19:56:16,995][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch password=><password>, hosts=>[//es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200], index=>"im_chat_info", id=>"2a372f8fc3ac0cb2808bf93a8efec032a624a042102987a0d5be0f79dbd5ede6", document_id=>"%{[@metadata][_id]}", user=>"elastic", document_type=>"%{[@metadata][_type]}", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_b02cebbc-0970-4e9c-bd0e-2c3b96b3be64", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ilm_enabled=>false, ilm_rollover_alias=>"logstash", ilm_pattern=>"{now/d}-000001", ilm_policy=>"logstash-policy", action=>"index", ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2019-12-23T19:56:17,089][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>6000, "pipeline.batch.delay"=>50}
[2019-12-23T19:56:17,418][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://elastic:xxxxxx@es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200/]}}
[2019-12-23T19:56:17,645][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://elastic:xxxxxx@es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200/"}
[2019-12-23T19:56:17,713][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2019-12-23T19:56:17,718][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2019-12-23T19:56:17,742][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200"]}
[2019-12-23T19:56:17,751][INFO ][logstash.outputs.elasticsearch] Using default mapping template
[2019-12-23T19:56:17,772][WARN ][logstash.pipeline        ] CAUTION: Recommended inflight events max exceeded! Logstash will run with up to 48000 events in memory in your current configuration. If your message sizes are large this may cause instability with the default heap size. Please consider setting a non-standard heap size, changing the batch size (currently 6000), or changing the number of pipeline workers (currently 8) {:pipeline_id=>"main", :thread=>"#<Thread:0x7b93ff75 run>"}
[2019-12-23T19:56:17,773][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2019-12-23T19:56:18,056][INFO ][logstash.pipeline        ] Pipeline started successfully {:pipeline_id=>"main", :thread=>"#<Thread:0x7b93ff75 run>"}
[2019-12-23T19:56:18,094][INFO ][logstash.agent           ] Pipelines running {:count=>1, :running_pipelines=>[:main], :non_running_pipelines=>[]}
[2019-12-23T19:56:18,356][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2019-12-23T20:04:48,429][INFO ][logstash.pipeline        ] Pipeline has terminated {:pipeline_id=>"main", :thread=>"#<Thread:0x7b93ff75 run>"}
[2019-12-23T20:05:02,858][INFO ][logstash.setting.writabledirectory] Creating directory {:setting=>"path.queue", :path=>"data/summary_hour_rule_action_log/queue"}
[2019-12-23T20:05:02,864][INFO ][logstash.setting.writabledirectory] Creating directory {:setting=>"path.dead_letter_queue", :path=>"data/summary_hour_rule_action_log/dead_letter_queue"}
[2019-12-23T20:05:03,136][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2019-12-23T20:05:03,144][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.7.0"}
[2019-12-23T20:05:03,166][INFO ][logstash.agent           ] No persistent UUID file found. Generating new UUID {:uuid=>"faf0c4c3-08ad-448e-a771-382df84f4082", :path=>"data/summary_hour_rule_action_log/uuid"}
[2019-12-23T20:05:07,681][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch password=><password>, hosts=>[//es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200], index=>"summary_hour_rule_action_log", id=>"9c67adae22fbc5c51cb80d23230be761539871019ba03499c875a7ae0fab53b1", document_id=>"%{[@metadata][_id]}", user=>"elastic", document_type=>"%{[@metadata][_type]}", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_d66c5c51-9dbe-4f10-b601-33bc9a8c11cd", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ilm_enabled=>false, ilm_rollover_alias=>"logstash", ilm_pattern=>"{now/d}-000001", ilm_policy=>"logstash-policy", action=>"index", ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2019-12-23T20:05:07,744][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>6000, "pipeline.batch.delay"=>50}
[2019-12-23T20:05:08,110][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://elastic:xxxxxx@es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200/]}}
[2019-12-23T20:05:08,319][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://elastic:xxxxxx@es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200/"}
[2019-12-23T20:05:08,366][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2019-12-23T20:05:08,369][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2019-12-23T20:05:08,388][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200"]}
[2019-12-23T20:05:08,397][INFO ][logstash.outputs.elasticsearch] Using default mapping template
[2019-12-23T20:05:08,408][WARN ][logstash.pipeline        ] CAUTION: Recommended inflight events max exceeded! Logstash will run with up to 48000 events in memory in your current configuration. If your message sizes are large this may cause instability with the default heap size. Please consider setting a non-standard heap size, changing the batch size (currently 6000), or changing the number of pipeline workers (currently 8) {:pipeline_id=>"main", :thread=>"#<Thread:0x673f8fce run>"}
[2019-12-23T20:05:08,428][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2019-12-23T20:05:08,806][INFO ][logstash.pipeline        ] Pipeline started successfully {:pipeline_id=>"main", :thread=>"#<Thread:0x673f8fce run>"}
[2019-12-23T20:05:08,860][INFO ][logstash.agent           ] Pipelines running {:count=>1, :running_pipelines=>[:main], :non_running_pipelines=>[]}
[2019-12-23T20:05:09,123][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2019-12-23T20:05:11,394][INFO ][logstash.pipeline        ] Pipeline has terminated {:pipeline_id=>"main", :thread=>"#<Thread:0x673f8fce run>"}
[2019-12-23T20:05:25,547][INFO ][logstash.setting.writabledirectory] Creating directory {:setting=>"path.queue", :path=>"data/chat_room/queue"}
[2019-12-23T20:05:25,553][INFO ][logstash.setting.writabledirectory] Creating directory {:setting=>"path.dead_letter_queue", :path=>"data/chat_room/dead_letter_queue"}
[2019-12-23T20:05:25,860][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2019-12-23T20:05:25,867][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.7.0"}
[2019-12-23T20:05:25,891][INFO ][logstash.agent           ] No persistent UUID file found. Generating new UUID {:uuid=>"c7285326-8d25-4bee-8b7f-63c447b2de2f", :path=>"data/chat_room/uuid"}
[2019-12-23T20:05:30,194][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch password=><password>, hosts=>[//es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200], index=>"chat_room", id=>"0304387d2a689a3bc7b5d4eecbe99fc3609fb8d4981296dcb41b37c03aa4da89", document_id=>"%{[@metadata][_id]}", user=>"elastic", document_type=>"%{[@metadata][_type]}", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_b23860e5-4194-4aa4-b853-627049625219", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ilm_enabled=>false, ilm_rollover_alias=>"logstash", ilm_pattern=>"{now/d}-000001", ilm_policy=>"logstash-policy", action=>"index", ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2019-12-23T20:05:30,258][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>6000, "pipeline.batch.delay"=>50}
[2019-12-23T20:05:30,658][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://elastic:xxxxxx@es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200/]}}
[2019-12-23T20:05:30,942][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://elastic:xxxxxx@es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200/"}
[2019-12-23T20:05:30,993][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2019-12-23T20:05:30,996][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2019-12-23T20:05:31,022][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200"]}
[2019-12-23T20:05:31,028][INFO ][logstash.outputs.elasticsearch] Using default mapping template
[2019-12-23T20:05:31,046][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2019-12-23T20:05:31,050][WARN ][logstash.pipeline        ] CAUTION: Recommended inflight events max exceeded! Logstash will run with up to 48000 events in memory in your current configuration. If your message sizes are large this may cause instability with the default heap size. Please consider setting a non-standard heap size, changing the batch size (currently 6000), or changing the number of pipeline workers (currently 8) {:pipeline_id=>"main", :thread=>"#<Thread:0x60b5cee9 run>"}
[2019-12-23T20:05:31,444][INFO ][logstash.pipeline        ] Pipeline started successfully {:pipeline_id=>"main", :thread=>"#<Thread:0x60b5cee9 run>"}
[2019-12-23T20:05:31,499][INFO ][logstash.agent           ] Pipelines running {:count=>1, :running_pipelines=>[:main], :non_running_pipelines=>[]}
[2019-12-23T20:05:31,766][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2019-12-23T20:05:34,024][INFO ][logstash.pipeline        ] Pipeline has terminated {:pipeline_id=>"main", :thread=>"#<Thread:0x60b5cee9 run>"}
[2019-12-23T20:05:47,355][INFO ][logstash.setting.writabledirectory] Creating directory {:setting=>"path.queue", :path=>"data/qr_code_fans/queue"}
[2019-12-23T20:05:47,361][INFO ][logstash.setting.writabledirectory] Creating directory {:setting=>"path.dead_letter_queue", :path=>"data/qr_code_fans/dead_letter_queue"}
[2019-12-23T20:05:47,671][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2019-12-23T20:05:47,680][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.7.0"}
[2019-12-23T20:05:47,703][INFO ][logstash.agent           ] No persistent UUID file found. Generating new UUID {:uuid=>"c068e39c-9e0d-4485-a17f-22d791fec122", :path=>"data/qr_code_fans/uuid"}
[2019-12-23T20:05:52,034][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch password=><password>, hosts=>[//es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200], index=>"qr_code_fans", id=>"36db215f1c73f7103f32c3d3255f0c5f5830862e27afbca2827b148f7b698406", document_id=>"%{[@metadata][_id]}", user=>"elastic", document_type=>"%{[@metadata][_type]}", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_3fe05450-f910-40a3-a20d-526c228c42c8", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ilm_enabled=>false, ilm_rollover_alias=>"logstash", ilm_pattern=>"{now/d}-000001", ilm_policy=>"logstash-policy", action=>"index", ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2019-12-23T20:05:52,096][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>6000, "pipeline.batch.delay"=>50}
[2019-12-23T20:05:52,453][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://elastic:xxxxxx@es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200/]}}
[2019-12-23T20:05:52,647][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://elastic:xxxxxx@es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200/"}
[2019-12-23T20:05:52,693][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2019-12-23T20:05:52,697][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2019-12-23T20:05:52,716][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200"]}
[2019-12-23T20:05:52,725][INFO ][logstash.outputs.elasticsearch] Using default mapping template
[2019-12-23T20:05:52,737][WARN ][logstash.pipeline        ] CAUTION: Recommended inflight events max exceeded! Logstash will run with up to 48000 events in memory in your current configuration. If your message sizes are large this may cause instability with the default heap size. Please consider setting a non-standard heap size, changing the batch size (currently 6000), or changing the number of pipeline workers (currently 8) {:pipeline_id=>"main", :thread=>"#<Thread:0xb621b57 run>"}
[2019-12-23T20:05:52,747][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2019-12-23T20:05:53,112][INFO ][logstash.pipeline        ] Pipeline started successfully {:pipeline_id=>"main", :thread=>"#<Thread:0xb621b57 run>"}
[2019-12-23T20:05:53,162][INFO ][logstash.agent           ] Pipelines running {:count=>1, :running_pipelines=>[:main], :non_running_pipelines=>[]}
[2019-12-23T20:05:53,418][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2019-12-23T20:05:54,722][INFO ][logstash.pipeline        ] Pipeline has terminated {:pipeline_id=>"main", :thread=>"#<Thread:0xb621b57 run>"}
[2019-12-23T20:06:07,505][INFO ][logstash.setting.writabledirectory] Creating directory {:setting=>"path.queue", :path=>"data/cc-deal-form-test3/queue"}
[2019-12-23T20:06:07,513][INFO ][logstash.setting.writabledirectory] Creating directory {:setting=>"path.dead_letter_queue", :path=>"data/cc-deal-form-test3/dead_letter_queue"}
[2019-12-23T20:06:07,898][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2019-12-23T20:06:07,905][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.7.0"}
[2019-12-23T20:06:07,929][INFO ][logstash.agent           ] No persistent UUID file found. Generating new UUID {:uuid=>"c64a13c1-d45c-44c5-b864-89a54cb89bee", :path=>"data/cc-deal-form-test3/uuid"}
[2019-12-23T20:06:12,392][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch password=><password>, hosts=>[//es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200], index=>"cc-deal-form-test3", id=>"fdd5c3c2dfaedbd21d1cde05b189bb7fd204598fde4ac7b1d44dcb5ba3207765", document_id=>"%{[@metadata][_id]}", user=>"elastic", document_type=>"%{[@metadata][_type]}", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_d5097bc2-e6a9-499b-89ce-1e9978c47914", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ilm_enabled=>false, ilm_rollover_alias=>"logstash", ilm_pattern=>"{now/d}-000001", ilm_policy=>"logstash-policy", action=>"index", ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2019-12-23T20:06:12,457][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>6000, "pipeline.batch.delay"=>50}
[2019-12-23T20:06:12,882][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://elastic:xxxxxx@es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200/]}}
[2019-12-23T20:06:13,102][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://elastic:xxxxxx@es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200/"}
[2019-12-23T20:06:13,147][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2019-12-23T20:06:13,150][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2019-12-23T20:06:13,168][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200"]}
[2019-12-23T20:06:13,177][INFO ][logstash.outputs.elasticsearch] Using default mapping template
[2019-12-23T20:06:13,189][WARN ][logstash.pipeline        ] CAUTION: Recommended inflight events max exceeded! Logstash will run with up to 48000 events in memory in your current configuration. If your message sizes are large this may cause instability with the default heap size. Please consider setting a non-standard heap size, changing the batch size (currently 6000), or changing the number of pipeline workers (currently 8) {:pipeline_id=>"main", :thread=>"#<Thread:0x64889073 run>"}
[2019-12-23T20:06:13,220][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2019-12-23T20:06:13,526][INFO ][logstash.pipeline        ] Pipeline started successfully {:pipeline_id=>"main", :thread=>"#<Thread:0x64889073 run>"}
[2019-12-23T20:06:13,574][INFO ][logstash.agent           ] Pipelines running {:count=>1, :running_pipelines=>[:main], :non_running_pipelines=>[]}
[2019-12-23T20:06:13,798][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2019-12-23T20:06:20,278][INFO ][logstash.pipeline        ] Pipeline has terminated {:pipeline_id=>"main", :thread=>"#<Thread:0x64889073 run>"}
[2019-12-23T20:06:34,518][INFO ][logstash.setting.writabledirectory] Creating directory {:setting=>"path.queue", :path=>"data/chat_room_member/queue"}
[2019-12-23T20:06:34,525][INFO ][logstash.setting.writabledirectory] Creating directory {:setting=>"path.dead_letter_queue", :path=>"data/chat_room_member/dead_letter_queue"}
[2019-12-23T20:06:34,853][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2019-12-23T20:06:34,863][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.7.0"}
[2019-12-23T20:06:34,895][INFO ][logstash.agent           ] No persistent UUID file found. Generating new UUID {:uuid=>"3a54dfba-95af-4305-ae6d-503c473ee54f", :path=>"data/chat_room_member/uuid"}
[2019-12-23T20:06:39,443][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch password=><password>, hosts=>[//es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200], index=>"chat_room_member", id=>"d3ace191411c0a68b951dcd62c24c3a77c70a74ec9b02ec95681949648123239", document_id=>"%{[@metadata][_id]}", user=>"elastic", document_type=>"%{[@metadata][_type]}", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_0d8402d1-1dc2-417a-a283-b0559585e72e", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ilm_enabled=>false, ilm_rollover_alias=>"logstash", ilm_pattern=>"{now/d}-000001", ilm_policy=>"logstash-policy", action=>"index", ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2019-12-23T20:06:39,506][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>6000, "pipeline.batch.delay"=>50}
[2019-12-23T20:06:39,890][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://elastic:xxxxxx@es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200/]}}
[2019-12-23T20:06:40,099][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://elastic:xxxxxx@es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200/"}
[2019-12-23T20:06:40,159][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2019-12-23T20:06:40,162][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2019-12-23T20:06:40,187][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200"]}
[2019-12-23T20:06:40,191][INFO ][logstash.outputs.elasticsearch] Using default mapping template
[2019-12-23T20:06:40,209][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2019-12-23T20:06:40,215][WARN ][logstash.pipeline        ] CAUTION: Recommended inflight events max exceeded! Logstash will run with up to 48000 events in memory in your current configuration. If your message sizes are large this may cause instability with the default heap size. Please consider setting a non-standard heap size, changing the batch size (currently 6000), or changing the number of pipeline workers (currently 8) {:pipeline_id=>"main", :thread=>"#<Thread:0x3cb9a01c run>"}
[2019-12-23T20:06:40,629][INFO ][logstash.pipeline        ] Pipeline started successfully {:pipeline_id=>"main", :thread=>"#<Thread:0x3cb9a01c sleep>"}
[2019-12-23T20:06:40,673][INFO ][logstash.agent           ] Pipelines running {:count=>1, :running_pipelines=>[:main], :non_running_pipelines=>[]}
[2019-12-23T20:06:40,897][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2019-12-23T20:08:34,296][INFO ][logstash.pipeline        ] Pipeline has terminated {:pipeline_id=>"main", :thread=>"#<Thread:0x3cb9a01c run>"}
[2019-12-23T20:08:47,611][INFO ][logstash.setting.writabledirectory] Creating directory {:setting=>"path.queue", :path=>"data/add_friends/queue"}
[2019-12-23T20:08:47,616][INFO ][logstash.setting.writabledirectory] Creating directory {:setting=>"path.dead_letter_queue", :path=>"data/add_friends/dead_letter_queue"}
[2019-12-23T20:08:47,886][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2019-12-23T20:08:47,893][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.7.0"}
[2019-12-23T20:08:47,916][INFO ][logstash.agent           ] No persistent UUID file found. Generating new UUID {:uuid=>"c32e5b84-9fbf-4810-b184-391ca38a8920", :path=>"data/add_friends/uuid"}
[2019-12-23T20:08:52,422][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch password=><password>, hosts=>[//es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200], index=>"add_friends", id=>"d2e44681373e1c4cc697305e3fd673f05694a5c80ba01dce39d88bec312d989b", document_id=>"%{[@metadata][_id]}", user=>"elastic", document_type=>"%{[@metadata][_type]}", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_912abce8-de4e-48fa-8e91-6d77de3d032e", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ilm_enabled=>false, ilm_rollover_alias=>"logstash", ilm_pattern=>"{now/d}-000001", ilm_policy=>"logstash-policy", action=>"index", ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2019-12-23T20:08:52,480][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>6000, "pipeline.batch.delay"=>50}
[2019-12-23T20:08:52,833][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://elastic:xxxxxx@es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200/]}}
[2019-12-23T20:08:53,035][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://elastic:xxxxxx@es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200/"}
[2019-12-23T20:08:53,081][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2019-12-23T20:08:53,083][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2019-12-23T20:08:53,102][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200"]}
[2019-12-23T20:08:53,114][INFO ][logstash.outputs.elasticsearch] Using default mapping template
[2019-12-23T20:08:53,123][WARN ][logstash.pipeline        ] CAUTION: Recommended inflight events max exceeded! Logstash will run with up to 48000 events in memory in your current configuration. If your message sizes are large this may cause instability with the default heap size. Please consider setting a non-standard heap size, changing the batch size (currently 6000), or changing the number of pipeline workers (currently 8) {:pipeline_id=>"main", :thread=>"#<Thread:0x6bbe50cf run>"}
[2019-12-23T20:08:53,153][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2019-12-23T20:08:53,534][INFO ][logstash.pipeline        ] Pipeline started successfully {:pipeline_id=>"main", :thread=>"#<Thread:0x6bbe50cf run>"}
[2019-12-23T20:08:53,584][INFO ][logstash.agent           ] Pipelines running {:count=>1, :running_pipelines=>[:main], :non_running_pipelines=>[]}
[2019-12-23T20:08:53,819][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2019-12-23T20:09:20,427][INFO ][logstash.pipeline        ] Pipeline has terminated {:pipeline_id=>"main", :thread=>"#<Thread:0x6bbe50cf run>"}
[2019-12-23T20:09:34,642][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2019-12-23T20:09:34,659][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.7.0"}
[2019-12-23T20:09:39,158][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch password=><password>, hosts=>[//es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200], index=>"summary_hour_behavior_log", id=>"f945e3cc868562b6c6342bb54032abed1457510a7f2b50322964a8e4f2f63b50", document_id=>"%{[@metadata][_id]}", user=>"elastic", document_type=>"%{[@metadata][_type]}", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_50306e36-b18a-40e7-9461-6ffdfa4cd160", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ilm_enabled=>false, ilm_rollover_alias=>"logstash", ilm_pattern=>"{now/d}-000001", ilm_policy=>"logstash-policy", action=>"index", ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2019-12-23T20:09:39,225][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>6000, "pipeline.batch.delay"=>50}
[2019-12-23T20:09:39,576][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://elastic:xxxxxx@es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200/]}}
[2019-12-23T20:09:39,785][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://elastic:xxxxxx@es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200/"}
[2019-12-23T20:09:39,849][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2019-12-23T20:09:39,853][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2019-12-23T20:09:39,877][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200"]}
[2019-12-23T20:09:39,884][INFO ][logstash.outputs.elasticsearch] Using default mapping template
[2019-12-23T20:09:39,901][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2019-12-23T20:09:39,903][WARN ][logstash.pipeline        ] CAUTION: Recommended inflight events max exceeded! Logstash will run with up to 48000 events in memory in your current configuration. If your message sizes are large this may cause instability with the default heap size. Please consider setting a non-standard heap size, changing the batch size (currently 6000), or changing the number of pipeline workers (currently 8) {:pipeline_id=>"main", :thread=>"#<Thread:0x56014c19 run>"}
[2019-12-23T20:09:40,309][INFO ][logstash.pipeline        ] Pipeline started successfully {:pipeline_id=>"main", :thread=>"#<Thread:0x56014c19 run>"}
[2019-12-23T20:09:40,365][INFO ][logstash.agent           ] Pipelines running {:count=>1, :running_pipelines=>[:main], :non_running_pipelines=>[]}
[2019-12-23T20:09:40,625][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2019-12-23T20:40:04,327][INFO ][logstash.pipeline        ] Pipeline has terminated {:pipeline_id=>"main", :thread=>"#<Thread:0x56014c19 run>"}
[2019-12-23T20:40:18,556][INFO ][logstash.setting.writabledirectory] Creating directory {:setting=>"path.queue", :path=>"data/index_customer_with_ex/queue"}
[2019-12-23T20:40:18,561][INFO ][logstash.setting.writabledirectory] Creating directory {:setting=>"path.dead_letter_queue", :path=>"data/index_customer_with_ex/dead_letter_queue"}
[2019-12-23T20:40:18,836][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2019-12-23T20:40:18,844][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.7.0"}
[2019-12-23T20:40:18,866][INFO ][logstash.agent           ] No persistent UUID file found. Generating new UUID {:uuid=>"de238dc0-8bc7-42c2-9fd6-12af9aed2302", :path=>"data/index_customer_with_ex/uuid"}
[2019-12-23T20:40:23,369][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch password=><password>, hosts=>[//es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200], index=>"index_customer_with_ex", id=>"095e5c38444437fc6e81922a3f8812712c7403a671e141c4935dff92521fb395", document_id=>"%{[@metadata][_id]}", user=>"elastic", document_type=>"%{[@metadata][_type]}", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_ac2bfc3b-c656-462a-8514-9568e93a0743", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ilm_enabled=>false, ilm_rollover_alias=>"logstash", ilm_pattern=>"{now/d}-000001", ilm_policy=>"logstash-policy", action=>"index", ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2019-12-23T20:40:23,431][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>6000, "pipeline.batch.delay"=>50}
[2019-12-23T20:40:23,800][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://elastic:xxxxxx@es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200/]}}
[2019-12-23T20:40:24,008][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://elastic:xxxxxx@es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200/"}
[2019-12-23T20:40:24,055][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2019-12-23T20:40:24,058][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2019-12-23T20:40:24,080][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200"]}
[2019-12-23T20:40:24,084][INFO ][logstash.outputs.elasticsearch] Using default mapping template
[2019-12-23T20:40:24,103][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2019-12-23T20:40:24,108][WARN ][logstash.pipeline        ] CAUTION: Recommended inflight events max exceeded! Logstash will run with up to 48000 events in memory in your current configuration. If your message sizes are large this may cause instability with the default heap size. Please consider setting a non-standard heap size, changing the batch size (currently 6000), or changing the number of pipeline workers (currently 8) {:pipeline_id=>"main", :thread=>"#<Thread:0x4a6a9221 run>"}
[2019-12-23T20:40:24,525][INFO ][logstash.pipeline        ] Pipeline started successfully {:pipeline_id=>"main", :thread=>"#<Thread:0x4a6a9221 run>"}
[2019-12-23T20:40:24,574][INFO ][logstash.agent           ] Pipelines running {:count=>1, :running_pipelines=>[:main], :non_running_pipelines=>[]}
[2019-12-23T20:40:24,858][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2019-12-23T20:51:03,414][INFO ][logstash.pipeline        ] Pipeline has terminated {:pipeline_id=>"main", :thread=>"#<Thread:0x4a6a9221 run>"}
[2019-12-23T20:51:17,249][INFO ][logstash.setting.writabledirectory] Creating directory {:setting=>"path.queue", :path=>"data/im_comment_info/queue"}
[2019-12-23T20:51:17,256][INFO ][logstash.setting.writabledirectory] Creating directory {:setting=>"path.dead_letter_queue", :path=>"data/im_comment_info/dead_letter_queue"}
[2019-12-23T20:51:17,564][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2019-12-23T20:51:17,572][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.7.0"}
[2019-12-23T20:51:17,595][INFO ][logstash.agent           ] No persistent UUID file found. Generating new UUID {:uuid=>"0946d964-76a5-4e12-933f-4af19376dca9", :path=>"data/im_comment_info/uuid"}
[2019-12-23T20:51:22,245][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch password=><password>, hosts=>[//es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200], index=>"im_comment_info", id=>"b4a250a58c5a30f306ccc1f8b411dd40787fedb5978700df36193c1bc0171049", document_id=>"%{[@metadata][_id]}", user=>"elastic", document_type=>"%{[@metadata][_type]}", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_a4e3151c-905b-4fcd-b380-35e500cc635a", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ilm_enabled=>false, ilm_rollover_alias=>"logstash", ilm_pattern=>"{now/d}-000001", ilm_policy=>"logstash-policy", action=>"index", ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2019-12-23T20:51:22,311][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>6000, "pipeline.batch.delay"=>50}
[2019-12-23T20:51:22,658][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://elastic:xxxxxx@es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200/]}}
[2019-12-23T20:51:22,883][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://elastic:xxxxxx@es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200/"}
[2019-12-23T20:51:22,951][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2019-12-23T20:51:22,955][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2019-12-23T20:51:22,993][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200"]}
[2019-12-23T20:51:22,998][INFO ][logstash.outputs.elasticsearch] Using default mapping template
[2019-12-23T20:51:23,020][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2019-12-23T20:51:23,023][WARN ][logstash.pipeline        ] CAUTION: Recommended inflight events max exceeded! Logstash will run with up to 48000 events in memory in your current configuration. If your message sizes are large this may cause instability with the default heap size. Please consider setting a non-standard heap size, changing the batch size (currently 6000), or changing the number of pipeline workers (currently 8) {:pipeline_id=>"main", :thread=>"#<Thread:0x10c25e run>"}
[2019-12-23T20:51:23,326][INFO ][logstash.pipeline        ] Pipeline started successfully {:pipeline_id=>"main", :thread=>"#<Thread:0x10c25e run>"}
[2019-12-23T20:51:23,371][INFO ][logstash.agent           ] Pipelines running {:count=>1, :running_pipelines=>[:main], :non_running_pipelines=>[]}
[2019-12-23T20:51:23,644][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2019-12-23T20:51:41,452][INFO ][logstash.pipeline        ] Pipeline has terminated {:pipeline_id=>"main", :thread=>"#<Thread:0x10c25e run>"}
[2019-12-23T20:51:55,053][INFO ][logstash.setting.writabledirectory] Creating directory {:setting=>"path.queue", :path=>"data/person_member/queue"}
[2019-12-23T20:51:55,059][INFO ][logstash.setting.writabledirectory] Creating directory {:setting=>"path.dead_letter_queue", :path=>"data/person_member/dead_letter_queue"}
[2019-12-23T20:51:55,345][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2019-12-23T20:51:55,352][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.7.0"}
[2019-12-23T20:51:55,375][INFO ][logstash.agent           ] No persistent UUID file found. Generating new UUID {:uuid=>"24614846-1fb1-4e91-9f45-2cb44c91dee1", :path=>"data/person_member/uuid"}
[2019-12-23T20:51:59,779][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch password=><password>, hosts=>[//es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200], index=>"person_member", id=>"7f2f074fc1d4404c1c390eab64ce00a42b4c4a3c6dad4f467308fdbad93a9360", document_id=>"%{[@metadata][_id]}", user=>"elastic", document_type=>"%{[@metadata][_type]}", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_b8adb47a-c480-4c3e-89f9-6c61f1bd38c0", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ilm_enabled=>false, ilm_rollover_alias=>"logstash", ilm_pattern=>"{now/d}-000001", ilm_policy=>"logstash-policy", action=>"index", ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2019-12-23T20:51:59,838][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>8, "pipeline.batch.size"=>6000, "pipeline.batch.delay"=>50}
[2019-12-23T20:52:00,208][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://elastic:xxxxxx@es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200/]}}
[2019-12-23T20:52:00,414][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://elastic:xxxxxx@es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200/"}
[2019-12-23T20:52:00,460][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}
[2019-12-23T20:52:00,463][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2019-12-23T20:52:00,483][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//es-cn-mp91g5cbq000g58ek.elasticsearch.aliyuncs.com:9200"]}
[2019-12-23T20:52:00,492][INFO ][logstash.outputs.elasticsearch] Using default mapping template
[2019-12-23T20:52:00,512][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2019-12-23T20:52:00,514][WARN ][logstash.pipeline        ] CAUTION: Recommended inflight events max exceeded! Logstash will run with up to 48000 events in memory in your current configuration. If your message sizes are large this may cause instability with the default heap size. Please consider setting a non-standard heap size, changing the batch size (currently 6000), or changing the number of pipeline workers (currently 8) {:pipeline_id=>"main", :thread=>"#<Thread:0x753b48e8 run>"}
[2019-12-23T20:52:00,896][INFO ][logstash.pipeline        ] Pipeline started successfully {:pipeline_id=>"main", :thread=>"#<Thread:0x753b48e8 run>"}
[2019-12-23T20:52:00,948][INFO ][logstash.agent           ] Pipelines running {:count=>1, :running_pipelines=>[:main], :non_running_pipelines=>[]}
[2019-12-23T20:52:01,216][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2019-12-23T20:52:13,025][INFO ][logstash.pipeline        ] Pipeline has terminated {:pipeline_id=>"main", :thread=>"#<Thread:0x753b48e8 run>"}
